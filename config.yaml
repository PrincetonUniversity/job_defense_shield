%YAML 1.1
---
#####################
## GLOBAL SETTINGS ##
#####################
jobstats-module-path: /home/jdh4/software/jobstats
violation-logs-path: /tigress/jdh4/utilities/job_defense_shield/violations
sender: cses@princeton.edu
reply-to: rcsystems@princeton.edu
greeting-method: getent
workday-method: usa
email-domain-name: "@princeton.edu"
report-emails:
  - halverson@princeton.edu
verbose: False
partition-renamings:
    datascience: datasci
external-emails:
    u12345: first.last@gmail.com
    u23456: first.last@gmail.com


#########################################
## CANCEL JOBS WITH 0% GPU UTILIZATION ##
#########################################
cancel-zero-gpu-jobs:
  cluster: della
  partitions:
    - pli-c
  sampling_period_minutes: 15 # minutes
  first_warning_minutes: 45   # minutes
  second_warning_minutes: 90  # minutes
  cancel_minutes: 105         # minutes
  email_file_first_warning:  "email/cancel_gpu_jobs_warning_1.txt"
  email_file_second_warning: "email/cancel_gpu_jobs_warning_2.txt"
  email_file_cancel:         "email/cancel_gpu_jobs_scancel_3.txt"
  jobid_cache_path: /projects/j/jdh4/utilities/job_defense_shield
  warnings_to_admin: False
  do_not_cancel: True
  admin_emails:
    - halverson@princeton.edu


####################################
## GPU MODEL TOO POWERFUL (ALERT) ##
####################################
gpu-model-too-powerful-1:
  cluster: della
  partitions:
    - gpu
  min_run_time: 61 # minutes
  num_cores_threshold: 1
  gpu_util_target: "50%"
  gpu_hours_threshold: 24 # gpu-hours
  email_file: "email/gpu_model_too_powerful.txt"
  excluded_users:
    - jzp
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu


##################################
## ZERO CPU UTILIZATION (ALERT) ##
##################################
zero-cpu-utilization-1:
  cluster: stellar
  partitions:
    - all
    - pppl
    - pu
  min_run_time: 61 # minutes
  email_file: "email/zero_cpu_utilization.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu

zero-cpu-utilization-2:
  cluster: della
  partitions:
    - cpu
    - physics
  min_run_time: 61 # minutes
  email_file: "email/zero_cpu_utilization.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu


#########################################
## GPU-HOURS AT 0% UTILIZATION (ALERT) ##
#########################################
zero-util-gpu-hours-1:
  cluster: della
  partitions:
    - gpu
    - pli-c
    - pli-p
    - pli
    - pli-lc
  min_run_time: 10              # minutes
  gpu_hours_threshold_user: 100 # hours
  gpu_hours_threshold_admin: 24 # hours
  email_file: "email/zero_util_gpu_hours.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu
    - kl5675@princeton.edu


####################################
## TOO MANY CORES PER GPU (ALERT) ##
####################################
too-many-cores-per-gpu-1:
  cluster: della
  partitions:
    - pli
    - pli-c
    - pli-p
    - pli-lc
  cluster_name: "Della (PLI)"
  cores_per_node: 96
  gpus_per_node: 8
  cores_per_gpu_target: 12
  cores_per_gpu_limit: 18
  min_run_time: 61 # minutes
  email_file: "email/too_many_cores_per_gpu.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu
    - kl5675@princeton.edu


#########################################
## TOO MUCH CPU MEMORY PER GPU (ALERT) ##
#########################################
too-much-cpu-mem-per-gpu-1:
  cluster: della
  partitions:
    - pli
    - pli-c
    - pli-p
    - pli-lc
  cluster_name: "Della (PLI)"
  cores_per_node: 96
  gpus_per_node: 8
  cpu_mem_per_node: 1000       # GB
  cpu_mem_per_gpu_target: 115  # GB
  cpu_mem_per_gpu_limit: 125   # GB
  mem_eff_thres: 0.8           # [0, 1]
  min_run_time: 61             # minutes
  email_file: "email/too_much_cpu_mem_per_gpu.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu
    - kl5675@princeton.edu

too-much-cpu-mem-per-gpu-2:
  cluster: della
  partitions:
    - gpu
  cluster_name: "Della (gpu)"
  cores_per_node: 48
  gpus_per_node: 4
  cpu_mem_per_node: 1000       # GB
  cpu_mem_per_gpu_target: 240  # GB
  cpu_mem_per_gpu_limit: 250   # GB
  mem_eff_thres: 0.8           # [0, 1]
  min_run_time: 61             # minutes
  email_file: "email/too_much_cpu_mem_per_gpu_2.txt"
  nodelist:
    - della-i14g1
    - della-i14g2
    - della-i14g3
    - della-i14g4
    - della-i14g5
    - della-i14g6
    - della-i14g7
    - della-i14g8
    - della-i14g9
    - della-i14g10
    - della-i14g11
    - della-i14g12
    - della-i14g13
    - della-i14g14
    - della-i14g15
    - della-i14g16
    - della-i14g17
    - della-i14g18
    - della-i14g19
    - della-i14g20
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu


#########################################
## MULTINODE CPU FRAGMENTATION (ALERT) ##
#########################################
multinode-cpu-fragmentation-1:
  cluster: della
  partitions:
    - cpu
  min_run_time: 120    # minutes
  cores_per_node: 32   # count
  cores_fraction: 0.5  # [0, 1]
  mem_per_node: 190    # GB
  safety_fraction: 0.2 # [0, 1]
  email_file: "email/multinode_cpu_fragmentation.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu

multinode-cpu-fragmentation-2:
  cluster: della
  partitions:
    - physics
  min_run_time: 61     # minutes
  cores_per_node: 40   # count
  cores_fraction: 0.8  # [0, 1]
  mem_per_node: 380    # GB
  safety_fraction: 0.2 # [0, 1]
  email_file: "email/multinode_cpu_fragmentation.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu

multinode-cpu-fragmentation-3:
  cluster: stellar
  partitions:
    - all
    - pppl
    - pu
  min_run_time: 61     # minutes
  cores_per_node: 96   # count
  cores_fraction: 0.8  # [0, 1]
  mem_per_node: 768    # GB
  safety_fraction: 0.2 # [0, 1]
  email_file: "email/multinode_cpu_fragmentation.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu


#########################################
## MULTINODE GPU FRAGMENTATION (ALERT) ##
#########################################
multinode-gpu-fragmentation-1:
  cluster: della
  partitions:
    - pli
    - pli-c
    - pli-p
    - pli-lc
  gpus_per_node: 8  # count
  min_run_time: 61  # minutes
  email_file: "email/multinode_gpu_fragmentation.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu
    - kl5675@princeton.edu

multinode-gpu-fragmentation-2:
  cluster: della
  partitions:
    - gpu
  gpus_per_node: 2  # count
  min_run_time: 61  # minutes
  email_file: "email/multinode_gpu_fragmentation_2.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu


########################
## LOW CPU EFFICIENCY ##
########################
low-cpu-efficiency-1:
  cluster: della
  partitions:
    - cpu
  eff_thres_pct: 60         # percent
  eff_target_pct: 90        # percent
  proportion_thres_pct: 2   # percent
  absolute_thres_hours: 50  # cpu-hours
  num_top_users: 15         # count
  min_run_time: 30          # minutes
  email_file: "email/low_cpu_efficiency.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu
    - msbc@princeton.edu

low-cpu-efficiency-2:
  cluster: della
  partitions:
    - physics
  eff_thres_pct: 50         # percent
  eff_target_pct: 90        # percent
  proportion_thres_pct: 2   # percent
  absolute_thres_hours: 100 # cpu-hours
  num_top_users: 3          # count
  min_run_time: 30          # minutes
  email_file: "email/low_cpu_efficiency.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu
    - msbc@princeton.edu

low-cpu-efficiency-3:
  cluster: stellar
  partitions:
    - all
    - pppl
    - pu
    - serial
  eff_thres_pct: 60         # percent
  eff_target_pct: 90        # percent
  proportion_thres_pct: 2   # percent
  absolute_thres_hours: 50  # cpu-hours
  num_top_users: 15         # count
  min_run_time: 30          # minutes
  email_file: "email/low_cpu_efficiency.txt"
  excluded_users:
    - aturing
    - hejia
    - einstein
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu
    - msbc@princeton.edu


########################
## LOW GPU EFFICIENCY ##
########################
low-gpu-efficiency-1:
  cluster: della
  partitions:
    - gpu
  eff_thres_pct: 15         # percent
  eff_target_pct: 50        # percent
  proportion_thres_pct: 2   # percent
  absolute_thres_hours: 50  # gpu-hours
  num_top_users: 15         # count
  min_run_time: 30          # minutes
  email_file: "email/low_gpu_efficiency.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu
    - msbc@princeton.edu

low-gpu-efficiency-2:
  cluster: della
  partitions:
    - pli-c   # core
    - pli     # campus, low priority
    - pli-p   # campus, higher priority than pli
    - pli-lc  # large campus
  eff_thres_pct: 40         # percent
  eff_target_pct: 75        # percent
  proportion_thres_pct: 2   # percent
  absolute_thres_hours: 168 # gpu-hours
  num_top_users: 5          # count
  min_run_time: 30          # minutes
  email_file: "email/low_gpu_efficiency.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu
    - kl5675@princeton.edu
    - msbc@princeton.edu


###################################################
## SERIAL CODE ALLOCATING MULTIPLE CORES (ALERT) ##
###################################################
serial-allocating-multiple-1:
    cluster: della
    partitions:
      - cpu
    cores_per_node: 32       # (optional)
    min_run_time: 61         # minutes
    cpu_hours_threshold: 100 # cpu-hours
    lower_ratio: 0.85        # [0, 1]
    num_top_users: 5
    email_file: "email/serial_allocating_multiple.txt"
    admin_emails:
      - halverson@princeton.edu
      - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com


########################
## EXCESS TIME LIMITS ##
########################
excessive-time-1:
  cluster: della
  partitions:
    - cpu
  min_run_time: 61             # minutes
  absolute_thres_hours: 10000  # cpu-hours
  mean_ratio_threshold: 20     # [0%, 100%]
  median_ratio_threshold: 20   # [0%, 100%]
  num_top_users: 5
  num_jobs_display: 10
  email_file: "email/excessive_time.txt"
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu


#######################
## EXCESS CPU MEMORY ##
#######################
excess-cpu-memory-1:
  cluster: della
  partitions:
    - cpu
  min_run_time: 30        # minutes
  cores_per_node: 32      # count
  cores_fraction: 0.8     # [0, 1]
  mem_per_node: 190       # GB
  tb_hours_threshold: 65  # TB-hours
  ratio_threshold: 0.35
  mean_ratio_threshold: 0.35
  median_ratio_threshold: 0.35
  num_top_users: 10
  num_jobs_display: 10
  email_file: "email/excess_cpu_memory.txt"
  excluded_users:
    - aturing
    - einstein
    - vonholdt
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu

#e
xcess-cpu-memory-2:
  cluster: della
  partitions:
    - datasci
  min_run_time: 61 # minutes
  cores_per_node: 10000
  mem_per_core_default: 5.0
  tb_hours_per_day: 10000
  ratio_threshold: 0.25
  mean_ratio_threshold: 0.25
  median_ratio_threshold: 0.25
  num_top_users: 10
  num_jobs_display: 10
  email_file: "email/excess_cpu_memory.txt"
  excluded_users:
    - aturing
    - einstein
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu

#e
xcess-cpu-memory-3:
  cluster: stellar
  partitions:
    - all
    - pppl
    - pu
    - serial
  min_run_time: 61  # minutes
  cores_per_node: 76.8  # 0.8 * 96
  mem_per_core_default: 8.0  # 768.0 / 96
  tb_hours_per_day: 10000
  ratio_threshold: 0.25
  mean_ratio_threshold: 0.25
  median_ratio_threshold: 0.25
  num_top_users: 5
  num_jobs_display: 10
  email_file: "email/excess_cpu_memory.txt"
  excluded_users:
    - aturing
    - einstein
  admin_emails:
    - alerts-jobs-aaaalegbihhpknikkw2fkdx6gi@princetonrc.slack.com
    - halverson@princeton.edu
